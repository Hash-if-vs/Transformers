{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length= 4\n",
    "batch_size =1\n",
    "input_dim= 512\n",
    "d_model=512\n",
    "x=torch.randn((batch_size,sequence_length,input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1536, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_layer= nn.Linear(input_dim,3*d_model)\n",
    "qkv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1879,  0.3536,  0.0309,  ...,  0.1717, -0.0132, -1.5548],\n",
       "         [ 0.4204, -0.1364, -0.5351,  ...,  0.0685,  0.6685,  0.1447],\n",
       "         [ 0.6139,  0.3866, -0.0567,  ...,  0.4234, -0.4719, -0.2524],\n",
       "         [-0.0664, -0.5666, -0.2707,  ...,  0.1831, -1.0645,  0.0470]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv=qkv_layer(x)\n",
    "qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 200 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhbklEQVR4nO3dfWyV9f3/8dcppYcK9JR20kNjazvGBO+QgdQC+QbkxHIThIg6lg47JKCuxWEXhS4CI1MLhCkDKxVniiYw1G2AYgRZUbrFUqDIpogIjpsKOa2u6zm0hrb2XL8/yI6/AxUontPrc9rnIznJel1XL969hvbp51znHIdlWZYAAAAMEmP3AAAAABciUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYJ9buAa5GIBDQmTNn1LdvXzkcDrvHAQAAV8CyLJ09e1apqamKibn0GklUBsqZM2eUlpZm9xgAAOAq1NTU6LrrrrvkMVEZKH379pV0/gdMSEiweRoAAHAl/H6/0tLSgr/HLyUqA+V/T+skJCQQKAAARJkruT2Dm2QBAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGCcWLsHABA9Mha+bfcIEXFi2WS7RwBwAVZQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYJwOB0pFRYWmTJmi1NRUORwObdmy5TuPffjhh+VwOLRq1aqQ7fX19crNzVVCQoISExM1e/ZsNTY2dnQUAADQRXU4UJqamjR06FCVlJRc8rjNmzdrz549Sk1NvWhfbm6uDh06pJ07d2rbtm2qqKjQ3LlzOzoKAADoojr8YYETJ07UxIkTL3nM6dOnNW/ePO3YsUOTJ4d+CNfhw4e1fft27du3TyNGjJAkrVmzRpMmTdLKlSvbDRoAANC9hP0elEAgoJkzZ+rxxx/XTTfddNH+yspKJSYmBuNEkjwej2JiYlRVVdXuOZubm+X3+0MeAACg6+rwCsrlLF++XLGxsXr00Ufb3e/1etW/f//QIWJjlZSUJK/X2+73FBcXa+nSpeEeFcAFMha+bfcIACApzCso1dXV+sMf/qD169fL4XCE7bxFRUXy+XzBR01NTdjODQAAzBPWQPn73/+uuro6paenKzY2VrGxsTp58qR+/etfKyMjQ5LkdrtVV1cX8n3ffPON6uvr5Xa72z2v0+lUQkJCyAMAAHRdYX2KZ+bMmfJ4PCHbcnJyNHPmTM2aNUuSlJ2drYaGBlVXV2v48OGSpF27dikQCCgrKyuc4wAAgCjV4UBpbGzUsWPHgl8fP35cBw8eVFJSktLT05WcnBxyfM+ePeV2u3XDDTdIkoYMGaIJEyZozpw5Ki0tVWtrqwoKCjRjxgxewQMAACRdxVM8+/fv17BhwzRs2DBJUmFhoYYNG6bFixdf8Tk2bNigwYMHa/z48Zo0aZLGjBmjdevWdXQUAADQRXV4BWXs2LGyLOuKjz9x4sRF25KSkrRx48aO/tEAAKCb4LN4AACAcQgUAABgnLC/URsARJvLvUHdiWWTL7kfQPixggIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOLF2DwDAfhkL37Z7BKNdeH1OLJts0yRA98EKCgAAMA6BAgAAjNPhQKmoqNCUKVOUmpoqh8OhLVu2BPe1trZqwYIFuuWWW9S7d2+lpqbqgQce0JkzZ0LOUV9fr9zcXCUkJCgxMVGzZ89WY2Pj9/5hAABA19DhQGlqatLQoUNVUlJy0b6vv/5aBw4c0KJFi3TgwAH99a9/1ZEjR3T33XeHHJebm6tDhw5p586d2rZtmyoqKjR37tyr/ykAAECX4rAsy7rqb3Y4tHnzZk2bNu07j9m3b59GjhypkydPKj09XYcPH9aNN96offv2acSIEZKk7du3a9KkSfriiy+Umpp62T/X7/fL5XLJ5/MpISHhascHuj1ujr063CQLXJ2O/P6O+D0oPp9PDodDiYmJkqTKykolJiYG40SSPB6PYmJiVFVV1e45mpub5ff7Qx4AAKDrimignDt3TgsWLNDPfvazYCl5vV71798/5LjY2FglJSXJ6/W2e57i4mK5XK7gIy0tLZJjAwAAm0UsUFpbW3X//ffLsiytXbv2e52rqKhIPp8v+KipqQnTlAAAwEQReaO2/8XJyZMntWvXrpDnmdxut+rq6kKO/+abb1RfXy+3293u+ZxOp5xOZyRGBQAABgr7Csr/4uTo0aP629/+puTk5JD92dnZamhoUHV1dXDbrl27FAgElJWVFe5xAABAFOrwCkpjY6OOHTsW/Pr48eM6ePCgkpKSNGDAAN177706cOCAtm3bpra2tuB9JUlJSYqLi9OQIUM0YcIEzZkzR6WlpWptbVVBQYFmzJhxRa/gAQAAXV+HA2X//v0aN25c8OvCwkJJUl5enn7729/qzTfflCTddtttId/33nvvaezYsZKkDRs2qKCgQOPHj1dMTIymT5+u1atXX+WPAAAAupoOB8rYsWN1qbdOuZK3VUlKStLGjRs7+kcDAIBugk8zBroB3pANQLThwwIBAIBxCBQAAGAcnuIBgA663FNmfFYP8P2xggIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA48TaPQCA8MlY+LbdIwBAWLCCAgAAjMMKCgCE2eVWsk4sm9xJkwDRixUUAABgHAIFAAAYh0ABAADGIVAAAIBxuEkW6AJ4eTGAroYVFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABgE6WsfBtXhoOXEaHA6WiokJTpkxRamqqHA6HtmzZErLfsiwtXrxYAwYMUHx8vDwej44ePRpyTH19vXJzc5WQkKDExETNnj1bjY2N3+sHAQAAXUeHA6WpqUlDhw5VSUlJu/tXrFih1atXq7S0VFVVVerdu7dycnJ07ty54DG5ubk6dOiQdu7cqW3btqmiokJz5869+p8CAAB0KR1+J9mJEydq4sSJ7e6zLEurVq3Sk08+qalTp0qSXn31VaWkpGjLli2aMWOGDh8+rO3bt2vfvn0aMWKEJGnNmjWaNGmSVq5cqdTU1O/x4wAAgK4grPegHD9+XF6vVx6PJ7jN5XIpKytLlZWVkqTKykolJiYG40SSPB6PYmJiVFVV1e55m5ub5ff7Qx4AAKDrCmugeL1eSVJKSkrI9pSUlOA+r9er/v37h+yPjY1VUlJS8JgLFRcXy+VyBR9paWnhHBsAABgmKl7FU1RUJJ/PF3zU1NTYPRIAAIigsAaK2+2WJNXW1oZsr62tDe5zu92qq6sL2f/NN9+ovr4+eMyFnE6nEhISQh4AAKDrCmugZGZmyu12q7y8PLjN7/erqqpK2dnZkqTs7Gw1NDSouro6eMyuXbsUCASUlZUVznEAAECU6vCreBobG3Xs2LHg18ePH9fBgweVlJSk9PR0zZ8/X0899ZQGDRqkzMxMLVq0SKmpqZo2bZokaciQIZowYYLmzJmj0tJStba2qqCgQDNmzOAVPAAAQNJVBMr+/fs1bty44NeFhYWSpLy8PK1fv15PPPGEmpqaNHfuXDU0NGjMmDHavn27evXqFfyeDRs2qKCgQOPHj1dMTIymT5+u1atXh+HHAYDocaXvJnti2eQITwKYx2FZlmX3EB3l9/vlcrnk8/m4HwXQlf+iQ3QiUNBVdOT3d1S8igcAAHQvBAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjdPjTjAHYjw8HBNDVsYICAACMQ6AAAADj8BQPYBCeugGA81hBAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYJe6C0tbVp0aJFyszMVHx8vAYOHKjf/e53siwreIxlWVq8eLEGDBig+Ph4eTweHT16NNyjAACAKBX2QFm+fLnWrl2r559/XocPH9by5cu1YsUKrVmzJnjMihUrtHr1apWWlqqqqkq9e/dWTk6Ozp07F+5xAABAFIoN9wk/+OADTZ06VZMnT5YkZWRk6E9/+pP27t0r6fzqyapVq/Tkk09q6tSpkqRXX31VKSkp2rJli2bMmBHukQAAQJQJ+wrKqFGjVF5ers8++0yS9M9//lP/+Mc/NHHiREnS8ePH5fV65fF4gt/jcrmUlZWlysrKds/Z3Nwsv98f8gAAAF1X2FdQFi5cKL/fr8GDB6tHjx5qa2vT008/rdzcXEmS1+uVJKWkpIR8X0pKSnDfhYqLi7V06dJwjwoAAAwV9hWU119/XRs2bNDGjRt14MABvfLKK1q5cqVeeeWVqz5nUVGRfD5f8FFTUxPGiQEAgGnCvoLy+OOPa+HChcF7SW655RadPHlSxcXFysvLk9vtliTV1tZqwIABwe+rra3Vbbfd1u45nU6nnE5nuEcFAACGCvsKytdff62YmNDT9ujRQ4FAQJKUmZkpt9ut8vLy4H6/36+qqiplZ2eHexwAABCFwr6CMmXKFD399NNKT0/XTTfdpA8//FDPPvusHnzwQUmSw+HQ/Pnz9dRTT2nQoEHKzMzUokWLlJqaqmnTpoV7HAAAEIXCHihr1qzRokWL9Mtf/lJ1dXVKTU3VQw89pMWLFwePeeKJJ9TU1KS5c+eqoaFBY8aM0fbt29WrV69wjwMAAKKQw/r/3+I1Svj9frlcLvl8PiUkJNg9DhA2GQvftnsEGOjEssl2jwCERUd+f/NZPAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOGF/mTGAy+PVOgBwaaygAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOLF2DwB0JxkL37Z7BACICqygAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4vMwYAAz3XS9PP7FscidPAnQeVlAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcSISKKdPn9bPf/5zJScnKz4+Xrfccov2798f3G9ZlhYvXqwBAwYoPj5eHo9HR48ejcQoAAAgCoU9UP773/9q9OjR6tmzp9555x198skn+v3vf69+/foFj1mxYoVWr16t0tJSVVVVqXfv3srJydG5c+fCPQ4AAIhCYf8snuXLlystLU1lZWXBbZmZmcH/bVmWVq1apSeffFJTp06VJL366qtKSUnRli1bNGPGjHCPBAAAokzYV1DefPNNjRgxQvfdd5/69++vYcOG6aWXXgruP378uLxerzweT3Cby+VSVlaWKisrwz0OAACIQmEPlH//+99au3atBg0apB07duiRRx7Ro48+qldeeUWS5PV6JUkpKSkh35eSkhLcd6Hm5mb5/f6QBwAA6LrC/hRPIBDQiBEj9Mwzz0iShg0bpo8//lilpaXKy8u7qnMWFxdr6dKl4RwT6DQZC9+2ewQAiDphX0EZMGCAbrzxxpBtQ4YM0alTpyRJbrdbklRbWxtyTG1tbXDfhYqKiuTz+YKPmpqacI8NAAAMEvZAGT16tI4cORKy7bPPPtP1118v6fwNs263W+Xl5cH9fr9fVVVVys7ObvecTqdTCQkJIQ8AANB1hf0pnscee0yjRo3SM888o/vvv1979+7VunXrtG7dOkmSw+HQ/Pnz9dRTT2nQoEHKzMzUokWLlJqaqmnTpoV7HAAAEIUclmVZ4T7ptm3bVFRUpKNHjyozM1OFhYWaM2dOcL9lWVqyZInWrVunhoYGjRkzRi+88IJ+/OMfX9H5/X6/XC6XfD4fqykwFveeoLOdWDbZ7hGAS+rI7++IBEqkESiIBgQKOhuBAtN15Pc3n8UDAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKADQRWQsfJuXt6PLIFAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxom1ewAg2vHGWAAQfqygAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgRD5Rly5bJ4XBo/vz5wW3nzp1Tfn6+kpOT1adPH02fPl21tbWRHgUAAESJiAbKvn379OKLL+rWW28N2f7YY4/prbfe0htvvKHdu3frzJkzuueeeyI5CgAAiCIRC5TGxkbl5ubqpZdeUr9+/YLbfT6fXn75ZT377LO68847NXz4cJWVlemDDz7Qnj17IjUOAACIIhELlPz8fE2ePFkejydke3V1tVpbW0O2Dx48WOnp6aqsrGz3XM3NzfL7/SEPAADQdcVG4qSbNm3SgQMHtG/fvov2eb1excXFKTExMWR7SkqKvF5vu+crLi7W0qVLIzEqAAAwUNhXUGpqavSrX/1KGzZsUK9evcJyzqKiIvl8vuCjpqYmLOcFAABmCvsKSnV1terq6vSTn/wkuK2trU0VFRV6/vnntWPHDrW0tKihoSFkFaW2tlZut7vdczqdTjmdznCPCgBdUsbCt9vdfmLZ5E6eBLh6YQ+U8ePH66OPPgrZNmvWLA0ePFgLFixQWlqaevbsqfLyck2fPl2SdOTIEZ06dUrZ2dnhHgcAAEShsAdK3759dfPNN4ds6927t5KTk4PbZ8+ercLCQiUlJSkhIUHz5s1Tdna27rjjjnCPAwAAolBEbpK9nOeee04xMTGaPn26mpublZOToxdeeMGOUQAAgIEclmVZdg/RUX6/Xy6XSz6fTwkJCXaPg27uu57vB0zDPSiwW0d+f/NZPAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMY8sbtQEAOh+f0YNowgoKAAAwDoECAACMQ6AAAADjECgAAMA43CQLfAc+BBAA7MMKCgAAMA6BAgAAjEOgAAAA4xAoAADAONwkCwDdHO8wCxOxggIAAIxDoAAAAOMQKAAAwDgECgAAMA43yaLb4p1iAcBcrKAAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjMMbtQEA2sWnHMNOrKAAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOOEPVCKi4t1++23q2/fvurfv7+mTZumI0eOhBxz7tw55efnKzk5WX369NH06dNVW1sb7lEAAECUCnug7N69W/n5+dqzZ4927typ1tZW3XXXXWpqagoe89hjj+mtt97SG2+8od27d+vMmTO65557wj0KAACIUmF/H5Tt27eHfL1+/Xr1799f1dXV+r//+z/5fD69/PLL2rhxo+68805JUllZmYYMGaI9e/bojjvuCPdIAAAgykT8HhSfzydJSkpKkiRVV1ertbVVHo8neMzgwYOVnp6uysrKds/R3Nwsv98f8gAAAF1XRAMlEAho/vz5Gj16tG6++WZJktfrVVxcnBITE0OOTUlJkdfrbfc8xcXFcrlcwUdaWlokxwYAADaLaKDk5+fr448/1qZNm77XeYqKiuTz+YKPmpqaME0IAABMFLHP4ikoKNC2bdtUUVGh6667Lrjd7XarpaVFDQ0NIasotbW1crvd7Z7L6XTK6XRGalQAQAdc+Bk9fDYPIiHsKyiWZamgoECbN2/Wrl27lJmZGbJ/+PDh6tmzp8rLy4Pbjhw5olOnTik7Ozvc4wAAgCgU9hWU/Px8bdy4UVu3blXfvn2D95W4XC7Fx8fL5XJp9uzZKiwsVFJSkhISEjRv3jxlZ2fzCh4AACApAoGydu1aSdLYsWNDtpeVlekXv/iFJOm5555TTEyMpk+frubmZuXk5OiFF14I9yhAu77rI+QBAOYIe6BYlnXZY3r16qWSkhKVlJSE+48HAABdAJ/FAwAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADBOxD4sEDAN7yALANGDFRQAAGAcVlAAAN/LhauTJ5ZNtmkSdCWsoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAADCKmPh27ysH98bgQIAAIzDy4zR5fBfbgAQ/VhBAQAAxiFQAACAcXiKB1GPp3QAM13un03ecRaXwgoKAAAwDoECAACMQ6AAAADjcA8KjMc9JgDQ/bCCAgAAjEOgAAAA4xAoAADAOAQKAAAwDjfJwhjcDAt0L9/1zzxv4AaJFRQAAGAgAgUAABiHp3gAAEa50qd7eSqoa2MFBQAAGIcVFEQMN70CiCRusu3aWEEBAADGYQUFV40VEgBApNi6glJSUqKMjAz16tVLWVlZ2rt3r53jAAAAQ9gWKK+99poKCwu1ZMkSHThwQEOHDlVOTo7q6ursGgkAABjCYVmWZccfnJWVpdtvv13PP/+8JCkQCCgtLU3z5s3TwoULL/m9fr9fLpdLPp9PCQkJnTGurXgqBQDQUSbeLNyR39+23IPS0tKi6upqFRUVBbfFxMTI4/GosrLyouObm5vV3Nwc/Nrn80k6/4N2B4Hmr+0eAQAQZUz8Hfm/ma5kbcSWQPnqq6/U1tamlJSUkO0pKSn69NNPLzq+uLhYS5cuvWh7WlpaxGYEACCauVbZPcF3O3v2rFwu1yWPiYpX8RQVFamwsDD4dSAQUH19vZKTk+VwOGyc7Or5/X6lpaWppqamWzxNdSlci/O4Dt/iWnyLa3Ee1+Fb0XwtLMvS2bNnlZqaetljbQmUH/zgB+rRo4dqa2tDttfW1srtdl90vNPplNPpDNmWmJgYyRE7TUJCQtT9BYsUrsV5XIdvcS2+xbU4j+vwrWi9FpdbOfkfW17FExcXp+HDh6u8vDy4LRAIqLy8XNnZ2XaMBAAADGLbUzyFhYXKy8vTiBEjNHLkSK1atUpNTU2aNWuWXSMBAABD2BYoP/3pT/Xll19q8eLF8nq9uu2227R9+/aLbpztqpxOp5YsWXLRU1fdEdfiPK7Dt7gW3+JanMd1+FZ3uRa2vQ8KAADAd+HDAgEAgHEIFAAAYBwCBQAAGIdAAQAAxiFQDHH33XcrPT1dvXr10oABAzRz5kydOXPG7rE61YkTJzR79mxlZmYqPj5eAwcO1JIlS9TS0mL3aLZ4+umnNWrUKF1zzTVd5o0Jr1RJSYkyMjLUq1cvZWVlae/evXaP1OkqKio0ZcoUpaamyuFwaMuWLXaPZIvi4mLdfvvt6tu3r/r3769p06bpyJEjdo9li7Vr1+rWW28NvkFbdna23nnnHbvHihgCxRDjxo3T66+/riNHjugvf/mLPv/8c9177712j9WpPv30UwUCAb344os6dOiQnnvuOZWWluo3v/mN3aPZoqWlRffdd58eeeQRu0fpVK+99poKCwu1ZMkSHThwQEOHDlVOTo7q6ursHq1TNTU1aejQoSopKbF7FFvt3r1b+fn52rNnj3bu3KnW1lbdddddampqsnu0Tnfddddp2bJlqq6u1v79+3XnnXdq6tSpOnTokN2jRYYFI23dutVyOBxWS0uL3aPYasWKFVZmZqbdY9iqrKzMcrlcdo/RaUaOHGnl5+cHv25ra7NSU1Ot4uJiG6eylyRr8+bNdo9hhLq6OkuStXv3brtHMUK/fv2sP/7xj3aPERGsoBiovr5eGzZs0KhRo9SzZ0+7x7GVz+dTUlKS3WOgk7S0tKi6uloejye4LSYmRh6PR5WVlTZOBlP4fD5J6vb/Xmhra9OmTZvU1NTUZT8ihkAxyIIFC9S7d28lJyfr1KlT2rp1q90j2erYsWNas2aNHnroIbtHQSf56quv1NbWdtE7SqekpMjr9do0FUwRCAQ0f/58jR49WjfffLPd49jio48+Up8+feR0OvXwww9r8+bNuvHGG+0eKyIIlAhauHChHA7HJR+ffvpp8PjHH39cH374od5991316NFDDzzwgKwu8Ea/Hb0OknT69GlNmDBB9913n+bMmWPT5OF3NdcCwHn5+fn6+OOPtWnTJrtHsc0NN9yggwcPqqqqSo888ojy8vL0ySef2D1WRPBW9xH05Zdf6j//+c8lj/nhD3+ouLi4i7Z/8cUXSktL0wcffBD1y3cdvQ5nzpzR2LFjdccdd2j9+vWKiek6HX01fyfWr1+v+fPnq6GhIcLT2a+lpUXXXHON/vznP2vatGnB7Xl5eWpoaOi2q4oOh0ObN28OuSbdTUFBgbZu3aqKigplZmbaPY4xPB6PBg4cqBdffNHuUcLOtg8L7A6uvfZaXXvttVf1vYFAQJLU3NwczpFs0ZHrcPr0aY0bN07Dhw9XWVlZl4oT6fv9negO4uLiNHz4cJWXlwd/GQcCAZWXl6ugoMDe4WALy7I0b948bd68We+//z5xcoFAINAlfk+0h0AxQFVVlfbt26cxY8aoX79++vzzz7Vo0SINHDgw6ldPOuL06dMaO3asrr/+eq1cuVJffvllcJ/b7bZxMnucOnVK9fX1OnXqlNra2nTw4EFJ0o9+9CP16dPH3uEiqLCwUHl5eRoxYoRGjhypVatWqampSbNmzbJ7tE7V2NioY8eOBb8+fvy4Dh48qKSkJKWnp9s4WefKz8/Xxo0btXXrVvXt2zd4L5LL5VJ8fLzN03WuoqIiTZw4Uenp6Tp79qw2btyo999/Xzt27LB7tMiw90VEsCzL+te//mWNGzfOSkpKspxOp5WRkWE9/PDD1hdffGH3aJ2qrKzMktTuozvKy8tr91q89957do8WcWvWrLHS09OtuLg4a+TIkdaePXvsHqnTvffee+3+/5+Xl2f3aJ3qu/6dUFZWZvdone7BBx+0rr/+eisuLs669tprrfHjx1vvvvuu3WNFDPegAAAA43StJ/gBAECXQKAAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwzv8DHVNgjwqvf1wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val= torch.histc(qkv,bins=200,min=-3,max=3)\n",
    "x_val= np.arange(-1,1,.01)*3\n",
    "plt.bar(x_val,y_val, align='center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads=8\n",
    "head_dim= d_model// num_heads\n",
    "qkv=qkv.reshape(batch_size,sequence_length,num_heads,3*head_dim)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv=qkv.permute(0,2,1,3)\n",
    "qkv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q,k,v= qkv.chunk(3,dim=-1)\n",
    "q.shape, k.shape , v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2338,  0.3945,  0.3104, -0.6006],\n",
       "          [ 0.3588,  0.3620, -0.1650,  0.2344],\n",
       "          [ 0.3666, -0.0674, -0.0649, -0.2284],\n",
       "          [-0.1949,  0.5415,  0.2887,  0.2662]],\n",
       "\n",
       "         [[ 0.3836,  0.2950, -0.2268, -0.3536],\n",
       "          [ 0.4433,  0.3283, -0.3240,  0.2819],\n",
       "          [-0.2426,  0.2668,  0.3948, -0.1664],\n",
       "          [-0.0544, -0.1226,  0.8586, -0.3759]],\n",
       "\n",
       "         [[ 0.4335, -0.0129, -0.0118, -0.2546],\n",
       "          [ 0.1668,  0.2917, -0.4349,  0.1476],\n",
       "          [-0.3265,  0.1003, -0.0500, -0.2322],\n",
       "          [-0.0431, -0.6092, -0.0560, -0.2494]],\n",
       "\n",
       "         [[ 0.5587, -0.4020,  0.1313, -0.0526],\n",
       "          [-0.2206,  0.2203,  0.0555,  0.2451],\n",
       "          [ 0.5459,  0.2093,  0.3547, -0.0205],\n",
       "          [-0.0528, -0.2485,  0.4023, -0.5981]],\n",
       "\n",
       "         [[-0.0056, -0.2956, -0.0198, -0.3341],\n",
       "          [-0.1474,  0.1739,  0.0471, -0.2213],\n",
       "          [-0.1744,  0.1263,  0.6642,  0.0600],\n",
       "          [ 0.4193,  0.1460,  0.5552, -0.4381]],\n",
       "\n",
       "         [[ 0.1060, -0.0598,  0.3369, -0.1222],\n",
       "          [ 0.1358, -0.2568,  0.1344, -0.0479],\n",
       "          [-0.1126, -0.4853,  0.2151,  0.8226],\n",
       "          [-0.2150, -0.0560,  0.0526,  0.2284]],\n",
       "\n",
       "         [[-0.4744, -0.0842,  0.3687,  0.2562],\n",
       "          [ 0.5645,  0.2952,  0.1314, -0.5776],\n",
       "          [ 0.3622,  0.1990, -0.3841, -0.7147],\n",
       "          [-0.0338, -0.4541, -0.6332,  0.4537]],\n",
       "\n",
       "         [[-0.3531, -0.3397,  0.2246, -0.1891],\n",
       "          [ 0.5746, -0.4246,  0.1656, -0.2461],\n",
       "          [-0.0336, -0.0938,  0.0174,  0.3115],\n",
       "          [-0.0121, -0.1123,  0.3436, -0.1980]]]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "d_k = q.size()[-1]\n",
    "scaled= torch.matmul(q, k.transpose(-2,-1))/math.sqrt(d_k)\n",
    "scaled.shape\n",
    "scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size(),float('-inf'))\n",
    "mask= torch.triu(mask,diagonal=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2338,    -inf,    -inf,    -inf],\n",
       "          [ 0.3588,  0.3620,    -inf,    -inf],\n",
       "          [ 0.3666, -0.0674, -0.0649,    -inf],\n",
       "          [-0.1949,  0.5415,  0.2887,  0.2662]],\n",
       "\n",
       "         [[ 0.3836,    -inf,    -inf,    -inf],\n",
       "          [ 0.4433,  0.3283,    -inf,    -inf],\n",
       "          [-0.2426,  0.2668,  0.3948,    -inf],\n",
       "          [-0.0544, -0.1226,  0.8586, -0.3759]],\n",
       "\n",
       "         [[ 0.4335,    -inf,    -inf,    -inf],\n",
       "          [ 0.1668,  0.2917,    -inf,    -inf],\n",
       "          [-0.3265,  0.1003, -0.0500,    -inf],\n",
       "          [-0.0431, -0.6092, -0.0560, -0.2494]],\n",
       "\n",
       "         [[ 0.5587,    -inf,    -inf,    -inf],\n",
       "          [-0.2206,  0.2203,    -inf,    -inf],\n",
       "          [ 0.5459,  0.2093,  0.3547,    -inf],\n",
       "          [-0.0528, -0.2485,  0.4023, -0.5981]],\n",
       "\n",
       "         [[-0.0056,    -inf,    -inf,    -inf],\n",
       "          [-0.1474,  0.1739,    -inf,    -inf],\n",
       "          [-0.1744,  0.1263,  0.6642,    -inf],\n",
       "          [ 0.4193,  0.1460,  0.5552, -0.4381]],\n",
       "\n",
       "         [[ 0.1060,    -inf,    -inf,    -inf],\n",
       "          [ 0.1358, -0.2568,    -inf,    -inf],\n",
       "          [-0.1126, -0.4853,  0.2151,    -inf],\n",
       "          [-0.2150, -0.0560,  0.0526,  0.2284]],\n",
       "\n",
       "         [[-0.4744,    -inf,    -inf,    -inf],\n",
       "          [ 0.5645,  0.2952,    -inf,    -inf],\n",
       "          [ 0.3622,  0.1990, -0.3841,    -inf],\n",
       "          [-0.0338, -0.4541, -0.6332,  0.4537]],\n",
       "\n",
       "         [[-0.3531,    -inf,    -inf,    -inf],\n",
       "          [ 0.5746, -0.4246,    -inf,    -inf],\n",
       "          [-0.0336, -0.0938,  0.0174,    -inf],\n",
       "          [-0.0121, -0.1123,  0.3436, -0.1980]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled+mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2338,    -inf,    -inf,    -inf],\n",
       "          [ 0.3588,  0.3620,    -inf,    -inf],\n",
       "          [ 0.3666, -0.0674, -0.0649,    -inf],\n",
       "          [-0.1949,  0.5415,  0.2887,  0.2662]],\n",
       "\n",
       "         [[ 0.3836,    -inf,    -inf,    -inf],\n",
       "          [ 0.4433,  0.3283,    -inf,    -inf],\n",
       "          [-0.2426,  0.2668,  0.3948,    -inf],\n",
       "          [-0.0544, -0.1226,  0.8586, -0.3759]],\n",
       "\n",
       "         [[ 0.4335,    -inf,    -inf,    -inf],\n",
       "          [ 0.1668,  0.2917,    -inf,    -inf],\n",
       "          [-0.3265,  0.1003, -0.0500,    -inf],\n",
       "          [-0.0431, -0.6092, -0.0560, -0.2494]],\n",
       "\n",
       "         [[ 0.5587,    -inf,    -inf,    -inf],\n",
       "          [-0.2206,  0.2203,    -inf,    -inf],\n",
       "          [ 0.5459,  0.2093,  0.3547,    -inf],\n",
       "          [-0.0528, -0.2485,  0.4023, -0.5981]],\n",
       "\n",
       "         [[-0.0056,    -inf,    -inf,    -inf],\n",
       "          [-0.1474,  0.1739,    -inf,    -inf],\n",
       "          [-0.1744,  0.1263,  0.6642,    -inf],\n",
       "          [ 0.4193,  0.1460,  0.5552, -0.4381]],\n",
       "\n",
       "         [[ 0.1060,    -inf,    -inf,    -inf],\n",
       "          [ 0.1358, -0.2568,    -inf,    -inf],\n",
       "          [-0.1126, -0.4853,  0.2151,    -inf],\n",
       "          [-0.2150, -0.0560,  0.0526,  0.2284]],\n",
       "\n",
       "         [[-0.4744,    -inf,    -inf,    -inf],\n",
       "          [ 0.5645,  0.2952,    -inf,    -inf],\n",
       "          [ 0.3622,  0.1990, -0.3841,    -inf],\n",
       "          [-0.0338, -0.4541, -0.6332,  0.4537]],\n",
       "\n",
       "         [[-0.3531,    -inf,    -inf,    -inf],\n",
       "          [ 0.5746, -0.4246,    -inf,    -inf],\n",
       "          [-0.0336, -0.0938,  0.0174,    -inf],\n",
       "          [-0.0121, -0.1123,  0.3436, -0.1980]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled+= mask\n",
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4992, 0.5008, 0.0000, 0.0000],\n",
       "          [0.4353, 0.2820, 0.2827, 0.0000],\n",
       "          [0.1588, 0.3317, 0.2576, 0.2519]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5287, 0.4713, 0.0000, 0.0000],\n",
       "          [0.2195, 0.3653, 0.4152, 0.0000],\n",
       "          [0.1941, 0.1813, 0.4837, 0.1408]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4688, 0.5312, 0.0000, 0.0000],\n",
       "          [0.2597, 0.3979, 0.3424, 0.0000],\n",
       "          [0.2969, 0.1685, 0.2931, 0.2415]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.3915, 0.6085, 0.0000, 0.0000],\n",
       "          [0.3937, 0.2812, 0.3251, 0.0000],\n",
       "          [0.2514, 0.2067, 0.3962, 0.1457]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4204, 0.5796, 0.0000, 0.0000],\n",
       "          [0.2144, 0.2896, 0.4960, 0.0000],\n",
       "          [0.3002, 0.2284, 0.3440, 0.1274]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5969, 0.4031, 0.0000, 0.0000],\n",
       "          [0.3250, 0.2239, 0.4511, 0.0000],\n",
       "          [0.1985, 0.2327, 0.2594, 0.3093]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.5669, 0.4331, 0.0000, 0.0000],\n",
       "          [0.4304, 0.3656, 0.2041, 0.0000],\n",
       "          [0.2608, 0.1713, 0.1432, 0.4247]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.7309, 0.2691, 0.0000, 0.0000],\n",
       "          [0.3340, 0.3145, 0.3515, 0.0000],\n",
       "          [0.2403, 0.2174, 0.3429, 0.1995]]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention= F.softmax(scaled,dim=-1)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values= torch.matmul(attention,v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4992, 0.5008, 0.0000, 0.0000],\n",
       "        [0.4353, 0.2820, 0.2827, 0.0000],\n",
       "        [0.1588, 0.3317, 0.2576, 0.2519]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, attention= scaled_dot_product(q,k,v,mask=mask)\n",
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values=values.reshape(batch_size,sequence_length,num_heads*head_dim)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=512, bias=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer= nn.Linear(d_model,d_model)\n",
    "linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1289, -0.0674,  0.2131,  ...,  0.1717,  0.0915, -0.1326],\n",
       "          [ 0.2200, -0.0280, -0.1859,  ..., -0.2328, -0.4718,  0.0925],\n",
       "          [-0.8161, -0.2505,  0.0442,  ...,  0.4321,  0.2553, -0.0793],\n",
       "          [-0.0787, -0.0902, -0.2238,  ..., -0.7640,  0.3664, -0.5680]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[[ 0.4123,  0.3856,  0.0387,  ...,  0.1213, -0.4502, -0.1384],\n",
       "          [-0.3134,  0.7883,  0.4490,  ...,  0.3652, -0.3706,  0.2227],\n",
       "          [ 0.6909, -0.5541,  0.6439,  ...,  0.1293,  0.1702, -0.0158],\n",
       "          [-0.7973, -0.5355, -0.4722,  ...,  0.2378, -0.2321, -0.4193]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " torch.Size([1, 4, 512]),\n",
       " torch.Size([1, 4, 512]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=linear_layer(values)\n",
    "out, values, out.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "materials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
